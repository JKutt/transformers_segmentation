{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCIP Complex geology\n",
    "\n",
    "Using PGI regularization with Gaussian mixture random markov field model and SAM segmentation lets try more complex geology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SimPEG import maps, utils, data, optimization, maps, regularization, inverse_problem, directives, inversion, data_misfit\n",
    "import discretize\n",
    "from discretize.utils import mkvc, refine_tree_xyz\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "import matplotlib.pyplot as plt\n",
    "from pymatsolver import Pardiso as Solver\n",
    "from SimPEG.electromagnetics.static import resistivity as dc, utils as dcutils\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as pe\n",
    "from scipy.stats import norm\n",
    "import scipy.sparse as sp\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import copy\n",
    "# setup the GMMRF\n",
    "from scipy import spatial, linalg\n",
    "from segment_anything import sam_model_registry\n",
    "from segment_anything import SamAutomaticMaskGenerator\n",
    "from PIL import Image\n",
    "from scipy import stats\n",
    "from matplotlib import cm\n",
    "from scipy.special import logsumexp\n",
    "from sklearn.mixture._gaussian_mixture import (\n",
    "    _compute_precision_cholesky,\n",
    ")\n",
    "\n",
    "# Python Version\n",
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "# Reproducible science\n",
    "seed = 12345\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "def calculate_iou(mask1, mask2):\n",
    "    \"\"\"\n",
    "    Calculate the Intersection over Union (IoU) between two binary masks.\n",
    "\n",
    "    Parameters:\n",
    "        mask1 (numpy.ndarray): The first binary mask.\n",
    "        mask2 (numpy.ndarray): The second binary mask.\n",
    "\n",
    "    Returns:\n",
    "        float: The Intersection over Union (IoU) score.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure the masks have the same shape\n",
    "    if mask1.shape != mask2.shape:\n",
    "        raise ValueError(\"Mask shapes do not match.\")\n",
    "\n",
    "    # Convert masks to binary (0 or 1) values\n",
    "    mask1 = np.array(mask1 > 0, dtype=np.uint8)\n",
    "    mask2 = np.array(mask2 > 0, dtype=np.uint8)\n",
    "\n",
    "    intersection = np.logical_and(mask1, mask2).sum()\n",
    "    union = np.logical_or(mask1, mask2).sum()\n",
    "\n",
    "    iou = intersection / union if union > 0 else 0.0\n",
    "    return iou\n",
    "\n",
    "\n",
    "class GaussianMixtureSam(utils.WeightedGaussianMixture):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_components,\n",
    "        mesh,\n",
    "        actv=None,\n",
    "        kdtree=None,\n",
    "        indexneighbors=None,\n",
    "        boreholeidx=None,\n",
    "        T=12.,\n",
    "        masks=None,\n",
    "        kneighbors=0,\n",
    "        norm=2,\n",
    "        init_params='kmeans',\n",
    "        max_iter=100,\n",
    "        covariance_type='full',\n",
    "        means_init=None,\n",
    "        n_init=10, \n",
    "        precisions_init=None,\n",
    "        random_state=None, \n",
    "        reg_covar=1e-06, \n",
    "        tol=0.001, \n",
    "        verbose=0,\n",
    "        verbose_interval=10, \n",
    "        warm_start=False, \n",
    "        weights_init=None,\n",
    "        anisotropy=None,\n",
    "        index_anisotropy=None, # Dictionary with anisotropy and index\n",
    "        index_kdtree=None,# List of KDtree\n",
    "        segmentation_model_checkpoint=r\"C:\\Users\\johnk\\Documents\\git\\jresearch\\PGI\\dcip\\sam_vit_h_4b8939.pth\",\n",
    "        #**kwargs\n",
    "    ):\n",
    "\n",
    "        super(GaussianMixtureSam, self).__init__(\n",
    "            n_components=n_components,\n",
    "            mesh=mesh,\n",
    "            actv=actv,\n",
    "            covariance_type=covariance_type,\n",
    "            init_params=init_params,\n",
    "            max_iter=max_iter,\n",
    "            means_init=means_init,\n",
    "            n_init=n_init,\n",
    "            precisions_init=precisions_init,\n",
    "            random_state=random_state,\n",
    "            reg_covar=reg_covar,\n",
    "            tol=tol,\n",
    "            verbose=verbose,\n",
    "            verbose_interval=verbose_interval,\n",
    "            warm_start=warm_start,\n",
    "            weights_init=weights_init,\n",
    "            #boreholeidx=boreholeidx\n",
    "            # **kwargs\n",
    "        )\n",
    "        # setKwargs(self, **kwargs)\n",
    "        self.kneighbors = kneighbors\n",
    "        self.T = T\n",
    "        self.boreholeidx = boreholeidx\n",
    "        self.anisotropy = anisotropy\n",
    "        self.norm = norm\n",
    "        self.masks = masks\n",
    "        self.mask_assignment = None\n",
    "        self.segmentation_model_checkpoint = segmentation_model_checkpoint\n",
    "\n",
    "        # load segmentation network model\n",
    "        sam = sam_model_registry[\"vit_h\"](checkpoint=self.segmentation_model_checkpoint)\n",
    "        self.mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "\n",
    "        if self.mesh.gridCC.ndim == 1:\n",
    "            xyz = np.c_[self.mesh.gridCC]\n",
    "        elif self.anisotropy is not None:\n",
    "            xyz = self.anisotropy.dot(self.mesh.gridCC.T).T\n",
    "        else:\n",
    "            xyz = self.mesh.gridCC\n",
    "        \n",
    "        if self.actv is None:\n",
    "            self.xyz = xyz\n",
    "        else:\n",
    "            self.xyz = xyz[self.actv]\n",
    "        \n",
    "        if kdtree is None:\n",
    "            print('Computing KDTree, it may take several minutes.')\n",
    "            self.kdtree = spatial.KDTree(self.xyz)\n",
    "        else:\n",
    "            self.kdtree = kdtree\n",
    "        \n",
    "        if indexneighbors is None:\n",
    "            print('Computing neighbors, it may take several minutes.')\n",
    "            _, self.indexneighbors = self.kdtree.query(self.xyz, k=self.kneighbors+1, p=self.norm)\n",
    "        else:\n",
    "            self.indexneighbors = indexneighbors\n",
    "\n",
    "        self.indexpoint = copy.deepcopy(self.indexneighbors)\n",
    "        self.index_anisotropy = index_anisotropy\n",
    "        self.index_kdtree = index_kdtree\n",
    "        if self.index_anisotropy is not None and self.mesh.gridCC.ndim != 1:\n",
    "\n",
    "            self.unitxyz = []\n",
    "            for i, anis in enumerate(self.index_anisotropy['anisotropy']):\n",
    "                self.unitxyz.append((anis).dot(self.xyz.T).T)\n",
    "\n",
    "            if self.index_kdtree is None:\n",
    "                self.index_kdtree = []\n",
    "                print('Computing rock unit specific KDTree, it may take several minutes.')\n",
    "                for i, anis in enumerate(self.index_anisotropy['anisotropy']):\n",
    "                    self.index_kdtree.append(spatial.KDTree(self.unitxyz[i]))\n",
    "\n",
    "    \n",
    "    def segment(\n",
    "            \n",
    "            self,\n",
    "            model:np.ndarray\n",
    "            \n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        \n",
    "            method that segments the input model and assigns new neighbors described\n",
    "            by the segmentation map\n",
    "\n",
    "            :param model: geophysical model\n",
    "            :type model: np.ndarray\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        model_normalized = np.exp(model) / np.abs(np.exp(model)).max()\n",
    "\n",
    "        image_rgb = Image.fromarray(np.uint8(cm.jet(model_normalized.reshape(self.mesh.shape_cells, order='F'))*255))\n",
    "        image_rgb = image_rgb.convert('RGB')\n",
    "\n",
    "        result = self.mask_generator.generate(np.asarray(image_rgb))\n",
    "\n",
    "\n",
    "        # ---------------------------------------------------------------------------------------------\n",
    "\n",
    "        # create a matrix that holds information about overlapping mask if they happen to\n",
    "\n",
    "        # this is done using intersection over union method\n",
    "\n",
    "        #\n",
    "\n",
    "        nlayers = len(result)\n",
    "\n",
    "        union_matrix = np.zeros((nlayers, nlayers))\n",
    "        for ii in range(nlayers):\n",
    "            for jj in range(nlayers):\n",
    "                iou_score = calculate_iou(result[ii]['segmentation'], result[jj]['segmentation'])\n",
    "                union_matrix[ii, jj] = iou_score\n",
    "                # print(\"IoU score:\", iou_score)\n",
    "\n",
    "        # ------------------------------------------------------------------------------------\n",
    "\n",
    "        # modify the overlap matrix to assign the proper neighbors mask in the case of onions\n",
    "\n",
    "        #\n",
    "\n",
    "        sub_union_matrix = union_matrix[1:, 1:].copy()\n",
    "        # print(f\"before sub-union: {sub_union_matrix}\\n\\n\")\n",
    "\n",
    "        removal = []\n",
    "\n",
    "        # check if masks have to be removed\n",
    "        for jj in range(sub_union_matrix.shape[0]):\n",
    "            \n",
    "            if np.count_nonzero(sub_union_matrix[jj, :]) > 1:\n",
    "\n",
    "                mask_index = np.nonzero(sub_union_matrix[jj, :])\n",
    "                \n",
    "                if mask_index[0].shape[0] == sub_union_matrix.shape[1]:\n",
    "                    print(\"\\n\\n removal\\n\\n\")\n",
    "                    removal.append(jj)\n",
    "\n",
    "        if len(removal) > 0:\n",
    "\n",
    "            for indx in removal:\n",
    "\n",
    "                result.pop(indx + 1)\n",
    "                sub_union_matrix = np.delete(sub_union_matrix, indx, 0)\n",
    "                sub_union_matrix = np.delete(sub_union_matrix, indx, 1)\n",
    "\n",
    "        # print(f\"modified sub-union: {sub_union_matrix}\\n\\n\")\n",
    "\n",
    "        # calculate how many non zero in a row of our overlap matrix\n",
    "        for jj in range(sub_union_matrix.shape[0]):\n",
    "\n",
    "            if np.count_nonzero(sub_union_matrix[jj, :]) > 1:\n",
    "\n",
    "                mask_index = np.nonzero(sub_union_matrix[jj, :])\n",
    "                # print(mask_index[0][-1])\n",
    "                sub_union_matrix[jj, mask_index[0][-1]] = 1\n",
    "                sub_union_matrix[jj, mask_index[0][0]] = 0\n",
    "\n",
    "        # print(f\"sub-union: {sub_union_matrix}\\n\\n\")\n",
    "        # --------------------------------------------------------------------------------------\n",
    "\n",
    "        # assign each cell a mask to assign it's neighbors\n",
    "\n",
    "        #\n",
    "\n",
    "        nlayers = len(result)\n",
    "\n",
    "        hx, hy = self.mesh.shape_cells\n",
    "        x = np.arange(hx)\n",
    "        y = np.arange(hy)\n",
    "        xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "        mask_locations = np.vstack([xx.flatten(), yy.flatten()])\n",
    "\n",
    "        mask_assignment = np.zeros(mask_locations.shape[1])\n",
    "\n",
    "        for ii in range(mask_locations.shape[1]):\n",
    "\n",
    "            for jj in range(nlayers - 1):\n",
    "\n",
    "                idx = np.vstack(np.where(result[jj + 1]['segmentation'] == True))\n",
    "\n",
    "                point_set = idx.T\n",
    "\n",
    "                # print(point_set.shape, np.vstack(idx).shape, xx.shape)\n",
    "                distances = np.sqrt(np.sum((point_set - mask_locations[:, ii].T)**2, axis=1))\n",
    "                # print(jj, mask_assignment[:, ii].T, point_set[0, :])\n",
    "                min_distance = np.min(distances)\n",
    "                \n",
    "                if min_distance == 0:\n",
    "\n",
    "                    # find which mask to assign\n",
    "                    idx1 = np.nonzero(sub_union_matrix[jj, :])\n",
    "                    mask_assignment[ii] = idx1[0][0] + 1\n",
    "\n",
    "        # plt.hist(mask_assignment, 100)\n",
    "        # plt.show()\n",
    "        # ----------------------------------------------------------------------------------------\n",
    "\n",
    "        # now update the indexpoint matrix\n",
    "\n",
    "        #\n",
    "\n",
    "        for kk in range(mask_assignment.shape[0]):\n",
    "\n",
    "            # check union matrix for the correct mask\n",
    "            union_index = int(mask_assignment[kk])\n",
    "            # print(union_index, sub_union_matrix.shape)\n",
    "            if union_index < 0:\n",
    "\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "                # print(sub_union_matrix[union_index, :])\n",
    "                mask_select = union_index\n",
    "\n",
    "                idx = np.vstack(np.where(result[mask_select]['segmentation'].flatten(order='F') == True))[0]\n",
    "                shape_idx = idx.shape[0]\n",
    "\n",
    "                # if the mask is smaller than the user defined number of neighbors\n",
    "                if idx.shape[0] < (self.kneighbors + 1):\n",
    "\n",
    "                    self.indexpoint[kk, :] = self.indexpoint[kk, 0]\n",
    "                    self.indexpoint[kk, -shape_idx:] = idx\n",
    "\n",
    "                # otherwise assign the entire mask\n",
    "                else:\n",
    "\n",
    "                    # print(f\"idx shape: {idx.shape} knei: {self.kneighbors} {shape_idx} {self.indexpoint.shape} {kk}\")\n",
    "                    # print(idx[:(self.kneighbors + 1)].shape, mask_locations.shape, mask_assignment.shape)\n",
    "                    self.indexpoint[kk, :] = idx[:(self.kneighbors + 1)]\n",
    "\n",
    "        self.masks = result\n",
    "        self.sub_union_matrix = sub_union_matrix\n",
    "        # print(np.bincount(onion.flatten()))\n",
    "\n",
    "        # fig, ax = plt.subplots(3,2, figsize=(10, 10))\n",
    "        # result[0].keys()\n",
    "        # ax[0, 0].imshow(np.log(model.reshape(self.mesh.shape_cells, order='F')).T)\n",
    "        # ax[0, 0].invert_yaxis()\n",
    "        # ax[0, 0].set_title('PGI recovered model')\n",
    "\n",
    "        # # for i in range(4):\n",
    "        # ax[0, 1].imshow(result[1]['segmentation'].T)\n",
    "        # ax[0, 1].invert_yaxis()\n",
    "        # ax[0, 1].set_title('SAM segmentation item 1')\n",
    "        # ax[1, 0].imshow(result[2]['segmentation'].T)\n",
    "        # ax[1, 0].invert_yaxis()\n",
    "        # ax[1, 0].set_title('SAM segmentation item 2')\n",
    "        # ax[1, 1].imshow(result[3]['segmentation'].T)\n",
    "        # ax[1, 1].invert_yaxis()\n",
    "        # ax[1, 1].set_title('SAM segmentation item 3')\n",
    "        # ax[2, 0].imshow(result[0]['segmentation'].T)\n",
    "        # ax[2, 0].invert_yaxis()\n",
    "        # ax[2, 0].set_title('SAM segmentation item 0')\n",
    "        # # ax[2, 1].imshow(result[4]['segmentation'].T)\n",
    "        # # ax[2, 1].invert_yaxis()\n",
    "        # # ax[2, 1].set_title('SAM segmentation item 0')\n",
    "        # plt.tight_layout()\n",
    "        # plt.show()\n",
    "\n",
    "\n",
    "    def predict(self, model):\n",
    "\n",
    "        # output quasi-geological model\n",
    "        geological_model = np.zeros(model.shape, dtype=int)\n",
    "        print('in predict!')\n",
    "        # loop through and take mean value of the assigned \n",
    "        for ii in range(model.shape[0]):\n",
    "\n",
    "            value = model[self.indexpoint[ii, :]].mean()\n",
    "            idx = (np.abs(self.means_ - value)).argmin()\n",
    "            geological_model[ii] = idx  # self.means_[idx]\n",
    "            # print(f\"assigning value: {geological_model[ii]}\")\n",
    "\n",
    "        return geological_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------\n",
    "\n",
    "# create a 2d mesh for a dc simulation\n",
    "\n",
    "#\n",
    "\n",
    "#2D mesh\n",
    "csx,  csy,  csz = 5.,  5.,  5.\n",
    "# Number of core cells in each direction\n",
    "ncx,  ncz = 163,  61\n",
    "# Number of padding cells to add in each direction\n",
    "npad = 12\n",
    "# Vectors of cell lengthts in each direction\n",
    "hx = [(csx, npad,  -1.5), (csx, ncx), (csx, npad,  1.5)]\n",
    "hz = [(csz, npad, -1.5), (csz, ncz)]\n",
    "# Create mesh\n",
    "mesh = discretize.TensorMesh([hx,  hz], x0=\"CN\")\n",
    "mesh.x0[1] = mesh.x0[1] + csz / 2.\n",
    "\n",
    "print(mesh)\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "# create a synthetic model for a dc simulation\n",
    "\n",
    "#\n",
    "\n",
    "# divide domain by  45* fault at 100 m\n",
    "fault_function = lambda x, slope, shift: slope * x + shift\n",
    "domain = np.ones(mesh.nC, dtype='int64')\n",
    "domain0 = mesh.gridCC[:,1] < fault_function(mesh.gridCC[:,0],-1,100.)\n",
    "domain[domain0] = 0\n",
    "\n",
    "# Layered Earth\n",
    "layered_model0 = 3 * np.ones(mesh.nC, dtype='int64')\n",
    "layered_model0[mesh.gridCC[:,1]>-50] = 2\n",
    "layered_model0[mesh.gridCC[:,1]>-25] = 1\n",
    "\n",
    "layered_model1 = 3 * np.ones(mesh.nC, dtype='int64')\n",
    "layered_model1[mesh.gridCC[:,1]>-75] = 2\n",
    "layered_model1[mesh.gridCC[:,1]>-50] = 1\n",
    "\n",
    "model = layered_model1\n",
    "model[domain0] = layered_model0[domain0]\n",
    "\n",
    "# Dike 45*\n",
    "dike0 = mesh.gridCC[:,1] > fault_function(mesh.gridCC[:,0],1, 100)\n",
    "dike1 = mesh.gridCC[:,1] < fault_function(mesh.gridCC[:,0],1, 175)\n",
    "dike = np.logical_and(dike0,dike1)\n",
    "\n",
    "model[dike]=4\n",
    "\n",
    "# plot\n",
    "fig,ax = plt.subplots(1,1,figsize=(10,5))\n",
    "mm = mesh.plotImage(model, ax=ax, pcolorOpts={'cmap':'viridis'})\n",
    "\n",
    "plt.gca().set_xlim([-1000,1000])\n",
    "plt.gca().set_ylim([-250,0])\n",
    "plt.gca().set_aspect(2)\n",
    "plt.colorbar(mm[0])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# define conductivities\n",
    "res_true = np.ones(mesh.nC)\n",
    "res_true[model==1]= 50\n",
    "res_true[model==2]= 250\n",
    "res_true[model==3]= 100\n",
    "res_true[model==4]= 10\n",
    "\n",
    "cond_true = 1./res_true\n",
    "\n",
    "mtrue = np.log(cond_true)\n",
    "\n",
    "xmin, xmax = -400., 400.\n",
    "ymin, ymax = -300., 0.\n",
    "zmin, zmax = 0, 0\n",
    "xyzlim = np.r_[[[xmin, xmax], [ymin, ymax]]]\n",
    "actcore,  meshCore = utils.mesh_utils.ExtractCoreMesh(xyzlim, mesh)\n",
    "actind = np.ones_like(actcore)\n",
    "print(meshCore)\n",
    "\n",
    "# plot\n",
    "fig,ax = plt.subplots(1,1,figsize=(10,5))\n",
    "mm = meshCore.plotImage(\n",
    "    \n",
    "    1/(cond_true)[actcore],\n",
    "    ax=ax,\n",
    "    pcolorOpts={'cmap':'viridis'}\n",
    "\n",
    ")\n",
    "\n",
    "utils.plot2Ddata(\n",
    "\n",
    "    meshCore.gridCC,mtrue[actcore],nx=500,ny=500,\n",
    "    contourOpts={'alpha':0},\n",
    "    #clim=[0,5],\n",
    "    ax=ax,\n",
    "    level=True,\n",
    "    ncontour=2,\n",
    "    levelOpts={'colors':'k','linewidths':2,'linestyles':'--'},\n",
    "    method='nearest'\n",
    "    \n",
    ")\n",
    "#plt.gca().set_ylim([-200,0])\n",
    "plt.gca().set_aspect(1)\n",
    "plt.colorbar(mm[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.linspace(25,250,10)\n",
    "\n",
    "xmin, xmax = -350., 350.\n",
    "ymin, ymax = 0., 0.\n",
    "zmin, zmax = 0, 0\n",
    "\n",
    "endl = np.array([[xmin, ymin, zmin], [xmax, ymax, zmax]])\n",
    "srclist = []\n",
    "\n",
    "for dipole in np.linspace(25,250,10):\n",
    "    \n",
    "    survey1 = dcutils.generate_dcip_survey(\n",
    "        \n",
    "        endl, survey_type=\"dipole-dipole\",\n",
    "        dim=mesh.dim,\n",
    "        a=dipole,\n",
    "        b=dipole,\n",
    "        n=16,\n",
    "        #d2flag=\"2.5D\"\n",
    "    \n",
    "    )\n",
    "    \n",
    "    srclist +=(survey1.source_list)\n",
    "\n",
    "survey = dc.Survey(srclist)\n",
    "\n",
    "# Setup Problem with exponential mapping and Active cells only in the core mesh\n",
    "expmap = maps.ExpMap(mesh)\n",
    "mapactive = maps.InjectActiveCells(\n",
    "    \n",
    "    mesh=mesh,\n",
    "    indActive=actcore,\n",
    "    valInactive=-np.log(100)\n",
    "\n",
    ")\n",
    "mapping = expmap * mapactive\n",
    "simulation = dc.Simulation2DNodal(\n",
    "    \n",
    "    mesh, \n",
    "    survey=survey, \n",
    "    sigmaMap=mapping,\n",
    "    solver=Solver,\n",
    "    nky=8\n",
    "\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "# create synthetic data and view psuedo-section\n",
    "\n",
    "#\n",
    "\n",
    "relative_measurement_error = 0.05\n",
    "dc_data = simulation.make_synthetic_data(\n",
    "    \n",
    "    mtrue[actcore],\n",
    "    relative_error=relative_measurement_error,\n",
    "    noise_floor=1e-4,\n",
    "    force=True,\n",
    "    add_noise=True,\n",
    "\n",
    ")\n",
    "\n",
    "relative_error_list = (np.abs(dc_data.standard_deviation/dc_data.dobs))\n",
    "print(relative_error_list.min())\n",
    "print(relative_error_list.max())\n",
    "print(np.median(relative_error_list))\n",
    "print(relative_error_list.mean())\n",
    "plt.hist(np.log10(relative_error_list), 50)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "m0 = np.log(1/100) * np.ones(mapping.nP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the inversion proceedure\n",
    "# Define a counter\n",
    "# Data misfit\n",
    "dmis = data_misfit.L2DataMisfit(data=dc_data, simulation=simulation)\n",
    "# Regularization\n",
    "regmap = maps.IdentityMap(nP=int(actcore.sum()))\n",
    "# reg = regularization.Sparse(mesh, indActive=active, mapping=regmap)\n",
    "\n",
    "reg = regularization.WeightedLeastSquares(\n",
    "    mesh, \n",
    "    active_cells=actcore,\n",
    "    mapping=regmap,\n",
    "    reference_model=m0\n",
    ")\n",
    "reg.alpha_s = 1\n",
    "reg.alpha_x = 100\n",
    "reg.alpha_y = 100\n",
    "reg.alpha_z = 100\n",
    "\n",
    "# Optimization object\n",
    "opt = optimization.ProjectedGNCG(maxIter=10, lower=-10, upper=10,\n",
    "                                 maxIterLS=20, maxIterCG=100, tolCG=1e-5)\n",
    "\n",
    "opt.remember('xc')\n",
    "\n",
    "# Set the inverse problem\n",
    "invProb = inverse_problem.BaseInvProblem(dmis,  reg,  opt)\n",
    "invProb.beta = 1e-2\n",
    "\n",
    "# Inversion directives\n",
    "Target = directives.TargetMisfit()\n",
    "betaSched = directives.BetaSchedule(coolingFactor=2.,  coolingRate=1.)\n",
    "updateSensW = directives.UpdateSensitivityWeights(threshold=1e-6,everyIter=False)\n",
    "update_Jacobi = directives.UpdatePreconditioner()\n",
    "inv = inversion.BaseInversion(invProb,  directiveList=[ # updateSensW, \n",
    "                                                       Target,\n",
    "                                                       betaSched,\n",
    "                                                    #    update_Jacobi,\n",
    "                                                       ])\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "# Run the inversion\n",
    "mopt = inv.run(m0)\n",
    "print('Inversion took {0} seconds'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the recovered model\n",
    "clim = [1, 500]\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,5))\n",
    "dat = meshCore.plotImage(1 / np.exp(mopt), ax=ax, pcolorOpts={'cmap':\"Spectral\"})\n",
    "plt.colorbar(dat[0])\n",
    "ax.set_title('Tikhonov inversion',fontsize=24)\n",
    "ax.set_aspect('equal')\n",
    "# ax.set_ylim([-15,0])\n",
    "ax.set_xlabel('x (m)',fontsize=22)\n",
    "ax.set_ylabel('z (m)',fontsize=22)\n",
    "ax.tick_params(labelsize=20)\n",
    "fig.subplots_adjust(right=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "gmmref = GaussianMixtureSam(\n",
    "    n_components=n, \n",
    "    mesh=meshCore,\n",
    "    kneighbors=24,\n",
    "    covariance_type='full',\n",
    ")\n",
    "gmmref.fit(mtrue[actcore].reshape(-1, 1))\n",
    "\n",
    "# Manually setting the GMM parameters\n",
    "## Order cluster by order of importance\n",
    "\n",
    "# Set cluster \n",
    "# res_true[model==1]= 50\n",
    "# res_true[model==2]= 250\n",
    "# res_true[model==3]= 100\n",
    "# res_true[model==4]= 10\n",
    "\n",
    "gmmref.means_ = np.r_[-np.log(10.), -np.log(50.), -np.log(100.), -np.log(250.)][:,np.newaxis]\n",
    "\n",
    "gmmref.covariances_ = np.array([[[0.001]],\n",
    "                             [[0.001]],\n",
    "                             [[0.001]],\n",
    "                             [[0.001]]])\n",
    "##Set clusters precision and Cholesky decomposition from variances\n",
    "gmmref.compute_clusters_precisions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of the data\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,5))\n",
    "hist, edges = np.histogram(-np.log(((dcutils.apparent_resistivity_from_voltage(survey, dc_data.dobs)))),bins=50, density=False)\n",
    "ax.bar(1./np.exp(edges[:-1]), hist, width=np.diff(1./np.exp(edges)), ec=\"k\", align=\"edge\",color='#8172B3');\n",
    "# ax.plot((1./np.exp(-4.72760309)*np.ones(2)),[0,50],linestyle='dashed',linewidth=2.,c='k')\n",
    "# ax.text(115,30,'Starting half-space\\nwhen no mean\\npetrophysical information\\nis available',fontsize=16)\n",
    "# ax.plot(100.*np.ones(2),[0,50],linestyle='dashed',linewidth=2.,c='k')\n",
    "# ax.text(98,20,'True\\nbackground\\nmean',fontsize=16,ha='right')\n",
    "ax.grid(True,which='both')\n",
    "ax.grid(True,which=\"major\",ls=\"-\")\n",
    "\n",
    "ax.set_xlabel('Data: Apparent Resistivity (Ohm-m)',fontsize=16)\n",
    "ax.tick_params(labelsize=14)\n",
    "ax.set_ylabel('Occurences',fontsize=16)\n",
    "# ax.set_xticks(np.r_[75,100,125,150])\n",
    "plt.show()\n",
    "# gmmref.weights_\n",
    "gmmref.plot_pdf()\n",
    "# testXplot = np.logspace(np.log(0.1), np.log(500), 1000,base=10)[:,np.newaxis]\n",
    "\n",
    "# ax.plot(testXplot, np.exp(gmmref.score_samples(-np.log(testXplot))) / 4,linewidth=3,label='True petrophysical\\ndistribution',c='r',\n",
    "#        path_effects=[pe.Stroke(linewidth=5, foreground='w'), pe.Normal()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / np.exp(-2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SimPEG.regularization import (\n",
    "\n",
    "    PGIsmallness,\n",
    ")\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "# creating directives and additional classes\n",
    "\n",
    "#\n",
    "\n",
    "#plot learned mref\n",
    "class plot_mref(directives.InversionDirective):\n",
    "    \n",
    "    def initialize(self):\n",
    "        self.start = 0\n",
    "        # self.endIter()\n",
    "    \n",
    "    def endIter(self):\n",
    "        # plot\n",
    "        # predicted = self.invProb.reg.gmmref.predict(self.opt.xc.reshape(-1, 1))\n",
    "        fig,ax = plt.subplots(3,1,figsize=(15,5))\n",
    "        mm = meshCore.plot_image(\n",
    "            self.opt.xc, ax=ax[0],\n",
    "            # clim=[-np.log(250),-np.log(10),],\n",
    "            pcolor_opts={'cmap':'Spectral'}\n",
    "        )\n",
    "        # fig,ax = plt.subplots(1,1,figsize=(15,5))\n",
    "        mm2 = meshCore.plot_image(\n",
    "            self.invProb.reg.objfcts[0].mref, ax=ax[1],\n",
    "            # clim=[-np.log(250),-np.log(10),],\n",
    "            pcolor_opts={'cmap':'Spectral'}\n",
    "        )\n",
    "        # ax.set_xlim([-750,750])\n",
    "        # ax.set_ylim([-250,0])\n",
    "        # fig,ax = plt.subplots(1,1,figsize=(15,5))\n",
    "        # mmpred = meshCore.plot_image(\n",
    "        #    predicted, ax=ax[3],\n",
    "        #     # clim=[-np.log(250),-np.log(10),],\n",
    "        #     pcolor_opts={'cmap':'Spectral'}\n",
    "        # )\n",
    "        \n",
    "        #plt.colorbar(mm[0])\n",
    "        utils.plot2Ddata(\n",
    "            meshCore.gridCC,mtrue[actcore],nx=500,ny=500,\n",
    "            contourOpts={'alpha':0},\n",
    "            #clim=[0,5],\n",
    "            ax=ax[0],\n",
    "            level=True,\n",
    "            ncontour=2,\n",
    "            levelOpts={'colors':'k','linewidths':2,'linestyles':'--'},\n",
    "            method='nearest'\n",
    "        )\n",
    "\n",
    "        ax[2].hist(self.opt.xc, 100)\n",
    "        # ax[2].set_aspect(1)\n",
    "\n",
    "        # ax[0].set_ylim([-15,0])\n",
    "        # ax[0].set_xlim([-15,15])\n",
    "        ax[0].set_aspect(1)\n",
    "        # ax[1].set_ylim([-15,0])\n",
    "        # ax[1].set_xlim([-15,15])\n",
    "        ax[1].set_aspect(1)\n",
    "        plt.show()\n",
    "\n",
    "# update the neighbors\n",
    "\n",
    "class update_segmentation_neighbours(directives.InversionDirective):\n",
    "    \n",
    "    def initialize(self):\n",
    "        self.count = 0\n",
    "        # self.endIter()\n",
    "\n",
    "        pgi_reg = self.reg.get_functions_of_type(PGIsmallness)\n",
    "        if len(pgi_reg) != 1:\n",
    "            raise UserWarning(\n",
    "                \"'PGI_UpdateParameters' requires one 'PGIsmallness' regularization \"\n",
    "                \"in the objective function.\"\n",
    "            )\n",
    "        self.pgi_reg = pgi_reg[0]\n",
    "    \n",
    "    def endIter(self):\n",
    "\n",
    "        print(f\"iteration: {self.opt.iter}\")\n",
    "        if self.count > 15:\n",
    "\n",
    "            self.pgi_reg.gmmref.segment(self.opt.xc)\n",
    "\n",
    "            self.pgi_reg.gmm = self.pgi_reg.gmmref\n",
    "\n",
    "            result = self.pgi_reg.gmm.masks\n",
    "            fig, ax = plt.subplots(3,2, figsize=(10, 10))\n",
    "            result[0].keys()\n",
    "            # ax[0, 0].imshow(np.log(model.reshape(self.mesh.shape_cells, order='F')).T)\n",
    "            ax[0, 0].invert_yaxis()\n",
    "            ax[0, 0].set_title('PGI recovered model')\n",
    "\n",
    "            # for i in range(4):\n",
    "            ax[0, 1].imshow(result[1]['segmentation'].T)\n",
    "            ax[0, 1].invert_yaxis()\n",
    "            ax[0, 1].set_title('SAM segmentation item 1')\n",
    "            if len(result) > 2:\n",
    "                ax[1, 0].imshow(result[2]['segmentation'].T)\n",
    "                ax[1, 0].invert_yaxis()\n",
    "                ax[1, 0].set_title('SAM segmentation item 2')\n",
    "                ax[1, 1].imshow(result[3]['segmentation'].T)\n",
    "                ax[1, 1].invert_yaxis()\n",
    "                ax[1, 1].set_title('SAM segmentation item 3')\n",
    "                ax[2, 0].imshow(result[0]['segmentation'].T)\n",
    "                ax[2, 0].invert_yaxis()\n",
    "                ax[2, 0].set_title('SAM segmentation item 0')\n",
    "                ax[2, 1].imshow(result[4]['segmentation'].T)\n",
    "                ax[2, 1].invert_yaxis()\n",
    "                ax[2, 1].set_title('SAM segmentation item 0')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        else:\n",
    "\n",
    "            self.count += 1\n",
    "\n",
    "\n",
    "class PGIUpdateParameters(directives.InversionDirective):\n",
    "    \"\"\"\n",
    "    This directive is to be used with regularization from regularization.pgi.\n",
    "\n",
    "    Custom PGI_UpdateParameters class that updates the reference model only\n",
    "    after the data misfits targets have been achieved.\n",
    "\n",
    "    It updates:\n",
    "        - the reference model and weights in the smallness (L2-approximation of PGI)\n",
    "        - the GMM as a MAP estimate between the prior and the current model\n",
    "    For more details, please consult:\n",
    "     - https://doi.org/10.1093/gji/ggz389\n",
    "    \"\"\"\n",
    "\n",
    "    verbose = False  # print info.  about the GMM at each iteration\n",
    "    update_rate = 1  # updates at each `update_rate` iterations\n",
    "    update_gmm = False  # update the GMM\n",
    "    zeta = (\n",
    "        1e10  # confidence in the prior proportions; default: high value, keep GMM fixed\n",
    "    )\n",
    "    nu = (\n",
    "        1e10  # confidence in the prior covariances; default: high value, keep GMM fixed\n",
    "    )\n",
    "    kappa = 1e10  # confidence in the prior means;default: high value, keep GMM fixed\n",
    "    update_covariances = (\n",
    "        True  # Average the covariances, If false: average the precisions\n",
    "    )\n",
    "    fixed_membership = None  # keep the membership of specific cells fixed\n",
    "    keep_ref_fixed_in_Smooth = True  # keep mref fixed in the Smoothness\n",
    "    update_reference_model = (\n",
    "        False  # don't update reference model until data misfits targets are hit\n",
    "    )\n",
    "\n",
    "    def initialize(self):\n",
    "        pgi_reg = self.reg.get_functions_of_type(PGIsmallness)\n",
    "        if len(pgi_reg) != 1:\n",
    "            raise UserWarning(\n",
    "                \"'PGI_UpdateParameters' requires one 'PGIsmallness' regularization \"\n",
    "                \"in the objective function.\"\n",
    "            )\n",
    "        self.pgi_reg = pgi_reg[0]\n",
    "\n",
    "    def endIter(self):\n",
    "        if self.opt.iter > 0 and self.opt.iter % self.update_rate == 0:\n",
    "            m = self.invProb.model\n",
    "            modellist = self.pgi_reg.wiresmap * m\n",
    "            model = np.c_[[a * b for a, b in zip(self.pgi_reg.maplist, modellist)]].T\n",
    "\n",
    "            if self.update_gmm and isinstance(\n",
    "                self.pgi_reg.gmmref, GaussianMixtureWithNonlinearRelationships\n",
    "            ):\n",
    "                clfupdate = GaussianMixtureWithNonlinearRelationshipsWithPrior(\n",
    "                    gmmref=self.pgi_reg.gmmref,\n",
    "                    zeta=self.zeta,\n",
    "                    kappa=self.kappa,\n",
    "                    nu=self.nu,\n",
    "                    verbose=self.verbose,\n",
    "                    prior_type=\"semi\",\n",
    "                    update_covariances=self.update_covariances,\n",
    "                    max_iter=self.pgi_reg.gmm.max_iter,\n",
    "                    n_init=self.pgi_reg.gmm.n_init,\n",
    "                    reg_covar=self.pgi_reg.gmm.reg_covar,\n",
    "                    weights_init=self.pgi_reg.gmm.weights_,\n",
    "                    means_init=self.pgi_reg.gmm.means_,\n",
    "                    precisions_init=self.pgi_reg.gmm.precisions_,\n",
    "                    random_state=self.pgi_reg.gmm.random_state,\n",
    "                    tol=self.pgi_reg.gmm.tol,\n",
    "                    verbose_interval=self.pgi_reg.gmm.verbose_interval,\n",
    "                    warm_start=self.pgi_reg.gmm.warm_start,\n",
    "                    fixed_membership=self.fixed_membership,\n",
    "                )\n",
    "                clfupdate = clfupdate.fit(model)\n",
    "\n",
    "            elif self.update_gmm and isinstance(\n",
    "                self.pgi_reg.gmmref, WeightedGaussianMixture\n",
    "            ):\n",
    "                clfupdate = GaussianMixtureWithPrior(\n",
    "                    gmmref=self.pgi_reg.gmmref,\n",
    "                    zeta=self.zeta,\n",
    "                    kappa=self.kappa,\n",
    "                    nu=self.nu,\n",
    "                    verbose=self.verbose,\n",
    "                    prior_type=\"semi\",\n",
    "                    update_covariances=self.update_covariances,\n",
    "                    max_iter=self.pgi_reg.gmm.max_iter,\n",
    "                    n_init=self.pgi_reg.gmm.n_init,\n",
    "                    reg_covar=self.pgi_reg.gmm.reg_covar,\n",
    "                    weights_init=self.pgi_reg.gmm.weights_,\n",
    "                    means_init=self.pgi_reg.gmm.means_,\n",
    "                    precisions_init=self.pgi_reg.gmm.precisions_,\n",
    "                    random_state=self.pgi_reg.gmm.random_state,\n",
    "                    tol=self.pgi_reg.gmm.tol,\n",
    "                    verbose_interval=self.pgi_reg.gmm.verbose_interval,\n",
    "                    warm_start=self.pgi_reg.gmm.warm_start,\n",
    "                    fixed_membership=self.fixed_membership,\n",
    "                )\n",
    "                clfupdate = clfupdate.fit(model)\n",
    "\n",
    "            else:\n",
    "                clfupdate = copy.deepcopy(self.pgi_reg.gmmref)\n",
    "\n",
    "            self.pgi_reg.gmm = clfupdate\n",
    "            membership = self.pgi_reg.gmm.predict(model)\n",
    "\n",
    "            if self.fixed_membership is not None:\n",
    "                membership[self.fixed_membership[:, 0]] = self.fixed_membership[:, 1]\n",
    "\n",
    "            if getattr(self.fixed_membership, \"shape\", [0, 0])[0] < len(membership):\n",
    "                self.pgi_reg._r_second_deriv = None\n",
    "\n",
    "            # Start updating reference model after we hit the data misfit targets\n",
    "            if self.data_misfits_achieved:\n",
    "                self.update_reference_model = True\n",
    "\n",
    "            # Update reference model after data misfits targets have been hit\n",
    "            if self.update_reference_model:\n",
    "                print(\"updating reference model\")\n",
    "                mref = mkvc(self.pgi_reg.gmm.means_[membership])\n",
    "                self.pgi_reg.reference_model = mref\n",
    "\n",
    "    @property\n",
    "    def data_misfits_achieved(self):\n",
    "        \"\"\"Returns True if data misfits have been achieved\"\"\"\n",
    "        return self.multi_target_misfits_directive.DM\n",
    "\n",
    "    @property\n",
    "    def directives(self):\n",
    "        \"\"\"List of all the directives in the :class:`SimPEG.inverison.BaseInversion``.\"\"\"\n",
    "        return self.inversion.directiveList.dList\n",
    "\n",
    "    @property\n",
    "    def multi_target_misfits_directive(self):\n",
    "        \"\"\"``MultiTargetMisfit`` directive in the :class:`SimPEG.inverison.BaseInversion``.\"\"\"\n",
    "        if not hasattr(self, \"_mtm_directive\"):\n",
    "            # Obtain multi target misfits directive from the directive list\n",
    "            multi_target_misfits_directive = [\n",
    "                directive\n",
    "                for directive in self.directives\n",
    "                if isinstance(directive, directives.MultiTargetMisfits)\n",
    "            ]\n",
    "            if not multi_target_misfits_directive:\n",
    "                raise UserWarning(\n",
    "                    \"No MultiTargetMisfits directive found in the current inversion. \"\n",
    "                    \"A MultiTargetMisfits directive is needed by the \"\n",
    "                    \"PGI_BetaAlphaSchedule directive.\"\n",
    "                )\n",
    "            (self._mtm_directive,) = multi_target_misfits_directive\n",
    "        return self._mtm_directive\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the regularization with GMM information\n",
    "idenMap = maps.IdentityMap(nP=m0.shape[0])\n",
    "wires = maps.Wires(('m', m0.shape[0]))\n",
    "reg_mean = regularization.PGI(\n",
    "    gmm=gmmref,\n",
    "    gmmref=gmmref, \n",
    "    mesh=mesh,\n",
    "    wiresmap=wires,\n",
    "    maplist=[idenMap],\n",
    "    reference_model=m0,\n",
    "    indActive=actcore\n",
    ")\n",
    "\n",
    "# Weighting\n",
    "reg_mean.alpha_s = 1\n",
    "reg_mean.alpha_x = 100\n",
    "reg_mean.alpha_y = 100\n",
    "# reg_mean.mrefInSmooth = True\n",
    "# reg_mean.approx_gradient = True\n",
    "\n",
    "\n",
    "# Optimization\n",
    "opt = optimization.ProjectedGNCG(maxIter=4, upper=np.inf, lower=-np.inf, tolCG=1E-5, maxIterLS=20, )\n",
    "opt.remember('xc')\n",
    "\n",
    "# Set the inverse problem\n",
    "invProb = inverse_problem.BaseInvProblem(dmis,  reg_mean,  opt)\n",
    "\n",
    "# Inversion directives\n",
    "betaIt = directives.PGI_BetaAlphaSchedule(\n",
    "    verbose=True, coolingFactor=5.,\n",
    "    warmingFactor=1., tolerance=0.05,\n",
    "    progress=0.1\n",
    ")\n",
    "targets = directives.MultiTargetMisfits(\n",
    "    TriggerSmall=True,\n",
    "    TriggerTheta=False,\n",
    "    verbose=True,\n",
    ")\n",
    "MrefInSmooth = directives.PGI_AddMrefInSmooth(verbose=True,  wait_till_stable=True, tolerance=0.0)\n",
    "petrodir = PGIUpdateParameters(\n",
    "    update_covariances=True,\n",
    "    kappa = 1e8,\n",
    "    nu = 1e8,\n",
    "    update_rate = 2,\n",
    "    update_reference_model=False\n",
    "    )\n",
    "update_sam = update_segmentation_neighbours()\n",
    "plot_iter_mref = plot_mref()\n",
    "updateSensW = directives.UpdateSensitivityWeights(threshold=5e-1, everyIter=False)\n",
    "update_Jacobi = directives.UpdatePreconditioner()\n",
    "invProb.beta = 1e-2\n",
    "inv = inversion.BaseInversion(invProb,\n",
    "                              directiveList=[\n",
    "                                            #  updateSensW,\n",
    "                                             update_sam,\n",
    "                                             petrodir,\n",
    "                                             targets, betaIt,\n",
    "                                            #  MrefInSmooth,\n",
    "                                             plot_iter_mref,\n",
    "                                            #  update_Jacobi,\n",
    "                                             ])\n",
    "\n",
    "# Run!\n",
    "mcluster = inv.run(m0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the recovered model\n",
    "clim = [1, 500]\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,5))\n",
    "dat = meshCore.plotImage(1 / np.exp(mcluster), ax=ax, pcolorOpts={'cmap':\"Spectral\"})\n",
    "plt.colorbar(dat[0])\n",
    "ax.set_title('Tikhonov inversion',fontsize=24)\n",
    "ax.set_aspect('equal')\n",
    "# ax.set_ylim([-15,0])\n",
    "ax.set_xlabel('x (m)',fontsize=22)\n",
    "ax.set_ylabel('z (m)',fontsize=22)\n",
    "ax.tick_params(labelsize=20)\n",
    "fig.subplots_adjust(right=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "j2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
